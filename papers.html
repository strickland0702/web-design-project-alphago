<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" type="text/css" href="css/html5reset.css">
        <link rel="stylesheet" type="text/css" href="css/style.css">
        <link rel="shortcut icon" type="image/png" href="images/alphago_icon.png"/>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway"/>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora"/>


        <title>AlphaGo: Papers</title>
    </head>
    <body>
        <div class="skip"><a href="#main">Skip to Main Content</a></div>

        <header>
            <nav>
                <img src="images/alphago_logo.png", alt="AlphaGo Logo" class="alphago-logo"/>

                <ul class="nav_links">
                    <li><a href="index.html">Home</a></li>
                    <li><a href="go.html">What is Go</a></li>
                    <li><a href="alphago.html">Approach</a></li>
                    <li><a href="events.html">Events</a></li>
                    <li><a href="papers.html" class="current-page">Papers</a></li>
                    
                </ul>
            </nav>

            <h1>Academic Papers</h1>
            <!-- <p>AlphaGo is the first computer program to defeat a professional human Go player, the first to defeat a Go world champion, and is arguably the strongest Go player in history.</p> -->

        </header>
        
        <main id="main">
            <div class="main-container">
                <div class="paper-item section-container">
                    <h2>Mastering the game of Go with Deep Neural Networks & Tree Search</h2>
                    <div>
                        <h3 class="abstract">Abstract<h3>
                            <p>A new approach to computer Go that combines Monte-Carlo tree search with deep neural networks that have been trained by supervised learning, from human expert games, and by reinforcement learning, from games of self-play. The first time ever that a computer program has defeated a human professional player.</p>
                            <!-- <img src="images/algorithm.png" alt="Algorithm behind AlphaGo"> -->
                            <div class="paper-link"><a href="https://storage.googleapis.com/deepmind-media/alphago/AlphaGoNaturePaper.pdf" aria-label="A">Download this paper</a></div>
                    </div>
 
                </div>

                <div class="shallow-green paper-item section-container">
                    <h2>Mastering the game of Go without Human Knowledge</h2>
                    <div>
                        <h3 class="abstract">Abstract<h3>
                            <p>A long-standing goal of artificial intelligence is an algorithm that learns, tabula rasa, superhuman proficiency in challenging domains. Recently, AlphaGo became the first program to defeat a world champion in the game of Go. The tree search in AlphaGo evaluated positions and selected moves using deep neural networks. These neural networks were trained by supervised learning from human expert moves, and by reinforcement learning from selfplay. Here, we introduce an algorithm based solely on reinforcement learning, without human data, guidance, or domain knowledge beyond game rules. AlphaGo becomes its own teacher: a neural network is trained to predict AlphaGo’s own move selections and also the winner of AlphaGo’s games. This neural network improves the strength of tree search, resulting in higher quality move selection and stronger self-play in the next iteration. Starting tabula rasa, our new program AlphaGo Zero achieved superhuman performance, winning 100-0 against the previously published, champion-defeating AlphaGo.</p>
                            <div class="paper-link"><a href="https://www.gwern.net/docs/rl/2017-silver.pdf" aria-label="B">Download this paper</a></div>
                    </div>


                </div>
                <div class="paper-item section-container">
                    <h2>A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play</h2>
                    <div>
                        <h3 class="abstract">Abstract<h3>
                            <p>The game of chess is the longest-studied domain in the history of artificial intelligence. The strongest programs are based on a combination of sophisticated search techniques, domain-specific adaptations, and handcrafted evaluation functions that have been refined by human experts over several decades. By contrast, the AlphaGo Zero program recently achieved superhuman performance in the game of Go by reinforcement learning from self-play. In this paper, we generalize this approach into a single AlphaZero algorithm that can achieve superhuman performance in many challenging games. Starting from random play and given no domain knowledge except the game rules, AlphaZero convincingly defeated a world champion program in the games of chess and shogi (Japanese chess), as well as Go.
                            </p>
                            <div class="paper-link"><a href="https://science.sciencemag.org/content/sci/362/6419/1140.full.pdf" aria-label="C">Download this paper</a></div>
                    </div>

                </div>

            </div>
            


        </main>

        <footer>
            <p>University of Michigan School of Information <br/>
                &copy; Rui Ding - Web Design Project Winter 2021</p>
        </footer>
    </body>
</html>